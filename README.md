# Top Hat - Raspberry Pi script
Script for analysis and processing of the data acquired by the head-mounted device

## PupilTracking_v2.py
Main script for the extraction of the pupil from the video recorded by the first and second device.

Inspired by the eye tracking algorithm of A. Meyer, et al. (2018)
Using the fast image inpainting based on coherence transport algorith writen in C by Folmar Bornemann and Tom Marz (2007), and adapted in Cython by A. Mayer, et al (2018)

## eyeCalibration.py
Generate a calibration file for the eye tracking position and angle

## mpuCalibration.py
Generate a calibration file for the motion sensor, based on calibration run performed during the implantation surgery

## DataExtraction_v1.py
Pipeline for data analysis, processing, and epoching of the first device

## ImportData.py
Import data from the .txt file generated by the first device

## ImportData_2.py
Import data from the .txt file generated by the second device

## ProcessData.py
Clean and analyze the data imported from the first device

## ProcessData_2.py
Clean and analyze the data imported from the second device

## EpochData.py
Create epochs of the eye tracking processed data for the first device

## EpochData_v2.py
Create epochs of the eye tracking and head movements processed data for the second device

## EpochVideo.py
Create epochs of the eye tracking video for the first device

## EpochVideo_2.py
Create epochs of the eye tracking video for the second device

## PlotData.py
Generate and save figures of each epochs for eye movements from the first device

## PlotData_2.py
Generate and save figures of each epochs for eye and head movements from the second device

# PlotEpoch.py
Plot a specific epoch to format the graphs of the first device

# PlotEpoch.py
Plot a specific epoch to format the graphs of the second device
